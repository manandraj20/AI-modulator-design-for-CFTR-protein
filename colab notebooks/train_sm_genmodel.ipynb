{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou8gJ8Vz_-nx",
        "outputId": "7eac6dfe-97ba-4e17-8d67-76c24f1497de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "TensorFlow version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "# import core libraries \n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import random as rn\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXgYrhD5ACsL"
      },
      "outputs": [],
      "source": [
        "# load Keras libraries\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.utils import Sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92QKaQUK-s6-",
        "outputId": "26c0e652-09d4-4d3f-d150-7b25480a58c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "Tue Dec 27 00:34:31 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P0    30W /  70W |    312MiB / 15109MiB |      1%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('change runtime to use the GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8X8PIfpTAJhP"
      },
      "outputs": [],
      "source": [
        "# set random seed\n",
        "seed = 777\n",
        "np.random.seed(seed)\n",
        "rn.seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LRxY1wO-w1U",
        "outputId": "a2b8f043-eb30-49c9-e67d-f55d56646bd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TW3DSo7n-yVx"
      },
      "outputs": [],
      "source": [
        "# create data load functions\n",
        "def load_data(data):\n",
        "    with open(data, 'r') as f:\n",
        "        smiles = [r.rstrip() for r in f]\n",
        "    return np.array(smiles)\n",
        "\n",
        "def load_dictionaries(input_dict):\n",
        "    with open(input_dict, 'r') as fp:\n",
        "        new_dict = json.load(fp)\n",
        "    return new_dict  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgAVkc77_JJV",
        "outputId": "b025a298-10e9-47f9-aa93-5e2d13012a16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training smiles shape: (351278,)\n",
            "Test smiles shape: (87820,)\n",
            "Sample training smile: \n",
            " Cc1cc(Oc2ccc(-c3nc4cc(C(N)=O)ccc4[nH]3)cc2)ccc1F\n"
          ]
        }
      ],
      "source": [
        "# load dataset & break into train/test sets\n",
        "smifile = '/drive/My Drive/chem_data/smiles_cleaned.smi'\n",
        "data = load_data(smifile)\n",
        "full_train, test = train_test_split(data, test_size=0.2, random_state=seed)\n",
        "print(\"Training smiles shape:\", full_train.shape)\n",
        "print(\"Test smiles shape:\", test.shape)\n",
        "print(\"Sample training smile: \\n\", full_train[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uN0fa6iPA3mz",
        "outputId": "7e88a465-c33f-4152-f730-ca6a68b989d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test file saved to disk\n"
          ]
        }
      ],
      "source": [
        "# save test file for smile generation\n",
        "np.save('/drive/My Drive/chem_data/test.npy', test)\n",
        "print('Test file saved to disk')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxkn_H0fBA9y",
        "outputId": "81245b3e-b053-49c8-817c-c9708f5ed62a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training dataset shape: (316150,)\n",
            "Validation dataset shape: (35128,)\n"
          ]
        }
      ],
      "source": [
        "# create our validation dataset\n",
        "val_split = 0.10\n",
        "train, val_set = train_test_split(full_train, test_size=val_split, random_state=seed)\n",
        "print(\"Training dataset shape:\", train.shape)\n",
        "print(\"Validation dataset shape:\", val_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-ZEX12OBD5H",
        "outputId": "c8194459-e03f-460c-9384-29cc7754c284"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Character set vocabulary length: 45\n",
            "Dictionary mapping characters-to-integers:\n",
            " {'n': 0, '[': 1, '\\\\': 2, 'E': 3, 'H': 4, ')': 5, 'B': 6, '9': 7, '2': 8, ']': 9, '7': 10, '!': 11, 't': 12, 's': 13, 'o': 14, 'c': 15, 'K': 16, '-': 17, '/': 18, 'l': 19, 'A': 20, 'r': 21, '@': 22, 'C': 23, '=': 24, '6': 25, 'N': 26, 'L': 27, 'a': 28, '5': 29, 'S': 30, 'T': 31, '#': 32, '+': 33, 'P': 34, 'i': 35, '(': 36, '8': 37, '1': 38, 'I': 39, 'e': 40, 'O': 41, '3': 42, 'F': 43, '4': 44}\n",
            "Dictionary mapping integers-to-characters:\n",
            " {'0': 'n', '1': '[', '2': '\\\\', '3': 'E', '4': 'H', '5': ')', '6': 'B', '7': '9', '8': '2', '9': ']', '10': '7', '11': '!', '12': 't', '13': 's', '14': 'o', '15': 'c', '16': 'K', '17': '-', '18': '/', '19': 'l', '20': 'A', '21': 'r', '22': '@', '23': 'C', '24': '=', '25': '6', '26': 'N', '27': 'L', '28': 'a', '29': '5', '30': 'S', '31': 'T', '32': '#', '33': '+', '34': 'P', '35': 'i', '36': '(', '37': '8', '38': '1', '39': 'I', '40': 'e', '41': 'O', '42': '3', '43': 'F', '44': '4'}\n"
          ]
        }
      ],
      "source": [
        "# load the Python dictionaries that map characters-to-integers and intergers-to-characters\n",
        "d1 = '/drive/My Drive/chem_data/char_to_int.json'\n",
        "d2 = '/drive/My Drive/chem_data/int_to_char.json'\n",
        "char_to_int = load_dictionaries(d1)\n",
        "int_to_char = load_dictionaries(d2)\n",
        "n_vocab = len(char_to_int)\n",
        "print(\"Character set vocabulary length:\", n_vocab)\n",
        "print(\"Dictionary mapping characters-to-integers:\\n\", char_to_int)\n",
        "print(\"Dictionary mapping integers-to-characters:\\n\", int_to_char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhU8r_3TBd33"
      },
      "outputs": [],
      "source": [
        "# create a function to turn the dataset into a supervised problem, add the beginning and ending character markers, \n",
        "# add padding for constant sequence length, and turn the sequence into a sequence of one-hot vectors\n",
        "def vectorize(smiles, embed, n_vocab):\n",
        "    one_hot = np.zeros((smiles.shape[0], embed, n_vocab), dtype=np.int8)\n",
        "    for i, smile in enumerate(smiles):\n",
        "        # encode the start\n",
        "        one_hot[i,0,char_to_int[\"!\"]] = 1\n",
        "        #encode the smiles characters\n",
        "        for j, c in enumerate(smile):\n",
        "            one_hot[i,j+1,char_to_int[c]] = 1\n",
        "        # encode the end of the smiles string\n",
        "        one_hot[i,len(smile)+1:,char_to_int[\"E\"]] = 1\n",
        "    # return two items, one for input and one for output\n",
        "    return one_hot[:,0:-1,:], one_hot[:,1:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iY2nnoYBrDa",
        "outputId": "32bc1744-d246-4f72-9b81-d7bb64a0b29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training input shape: (316150, 100, 45)\n",
            "Training output shape: (316150, 100, 45)\n",
            "Validation input shape: (35128, 100, 45)\n",
            "Validation output shape: (35128, 100, 45)\n",
            "Test input shape: (87820, 100, 45)\n",
            "Test output shape: (87820, 100, 45)\n"
          ]
        }
      ],
      "source": [
        "# create our X & y datasets\n",
        "embed = 101\n",
        "X_train, y_train = vectorize(train, embed, n_vocab)\n",
        "X_val, y_val = vectorize(val_set, embed, n_vocab)\n",
        "X_test, y_test = vectorize(test, embed, n_vocab)\n",
        "print(\"Training input shape:\", X_train.shape)\n",
        "print(\"Training output shape:\", y_train.shape)\n",
        "print(\"Validation input shape:\", X_val.shape)\n",
        "print(\"Validation output shape:\", y_val.shape)\n",
        "print(\"Test input shape:\", X_test.shape)\n",
        "print(\"Test output shape:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OGLLSKtDBu1s",
        "outputId": "580cf38d-248f-4a80-956a-8c2bb718ecfe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!O=c1ccc(OCCCN2CCN(c3csc4ccccc34)CC2)nn1-c1ccc(Cl)c(Cl)c1EEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEEE'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\".join([int_to_char[str(idx)] for idx in np.argmax(X_train[0,:,:], axis=1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7mIoJp1Bx3b"
      },
      "outputs": [],
      "source": [
        "# define the LSTM Chem model\n",
        "def lstm_model(X, y):\n",
        "    # define the encoder layers\n",
        "    enc_input = Input(shape=(X.shape[1:]))\n",
        "    _, state_h, state_c = LSTM(256, return_state=True)(enc_input)\n",
        "    states = Concatenate(axis=-1)([state_h, state_c])\n",
        "    bottle_neck = Dense(128, activation='relu')(states)\n",
        "\n",
        "    # define the decoder layers\n",
        "    state_h_decoded = Dense(256, activation='relu')(bottle_neck)\n",
        "    state_c_decoded = Dense(256, activation='relu')(bottle_neck)\n",
        "    encoder_states = [state_h_decoded, state_c_decoded]\n",
        "    dec_input = Input(shape=(X.shape[1:]))\n",
        "    dec1 = LSTM(256, return_sequences=True)(dec_input, initial_state=encoder_states)\n",
        "    output = Dense(y.shape[2], activation='softmax')(dec1)\n",
        "    \n",
        "    model = Model(inputs=[enc_input, dec_input], outputs=output)   \n",
        "    return model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bpl_LkzuB536",
        "outputId": "37c13ba7-ac97-45e7-f6a1-fd8a7e5a3950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 100, 45)]    0           []                               \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        309248      ['input_1[0][0]']                \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 512)          0           ['lstm[0][1]',                   \n",
            "                                                                  'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 128)          65664       ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, 100, 45)]    0           []                               \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 256)          33024       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 256)          33024       ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  (None, 100, 256)     309248      ['input_2[0][0]',                \n",
            "                                                                  'dense_1[0][0]',                \n",
            "                                                                  'dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 100, 45)      11565       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 761,773\n",
            "Trainable params: 761,773\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# instantiate our neural network model\n",
        "model = lstm_model(X_train, y_train)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zy5jIurGB88O"
      },
      "outputs": [],
      "source": [
        "# compile the model\n",
        "batch_size = 256\n",
        "steps_per_epoch = len(X_train) // batch_size\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(0.001, decay_steps=steps_per_epoch*50, decay_rate=1.0, staircase=False)\n",
        "opt = Adam()\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWHm3_7KCEX7"
      },
      "outputs": [],
      "source": [
        "# define our data sequence generator class\n",
        "class Data_Generator(Sequence):\n",
        "    def __init__(self, input_data, labels, batch_size):\n",
        "        self.input_data, self.labels = input_data, labels\n",
        "        self.batch_size = batch_size\n",
        "    \n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.input_data) / float(self.batch_size)))\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x = self.input_data[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        \n",
        "        batch_x, batch_y = np.array(x), np.array(y)\n",
        "        \n",
        "        return [batch_x, batch_x], batch_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHjs8fSOCIOH"
      },
      "outputs": [],
      "source": [
        "# create object instances of our sequence generator\n",
        "training_generator = Data_Generator(X_train, y_train, batch_size)\n",
        "validation_generator = Data_Generator(X_val, y_val, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDCnk5oTCK8s"
      },
      "outputs": [],
      "source": [
        "# create our callbacks\n",
        "file=\"/drive/My Drive/chem_data/LSTM_Chem_weights-{epoch:02d}-{acc:.4f}-{val_loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(file, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "rlrp = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-5)\n",
        "tb = TensorBoard(log_dir=\"/drive/My Drive/logs/chem/\", histogram_freq=1, write_graph=True, write_images=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0pkc5X6Dpj9",
        "outputId": "34d84b51-ebc2-486c-caaa-ef498ed58884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/225\n",
            "1234/1234 [==============================] - 69s 50ms/step - loss: 0.7959 - acc: 0.7523 - val_loss: 0.5494 - val_acc: 0.8189\n",
            "Epoch 2/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.5020 - acc: 0.8307 - val_loss: 0.4625 - val_acc: 0.8416\n",
            "Epoch 3/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.4408 - acc: 0.8481 - val_loss: 0.4197 - val_acc: 0.8541\n",
            "Epoch 4/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.4074 - acc: 0.8579 - val_loss: 0.3933 - val_acc: 0.8622\n",
            "Epoch 5/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.3852 - acc: 0.8648 - val_loss: 0.3744 - val_acc: 0.8683\n",
            "Epoch 6/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.3691 - acc: 0.8700 - val_loss: 0.3608 - val_acc: 0.8729\n",
            "Epoch 7/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.3534 - acc: 0.8756 - val_loss: 0.3351 - val_acc: 0.8828\n",
            "Epoch 8/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.3276 - acc: 0.8855 - val_loss: 0.3180 - val_acc: 0.8890\n",
            "Epoch 9/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.3142 - acc: 0.8902 - val_loss: 0.3084 - val_acc: 0.8922\n",
            "Epoch 10/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.3057 - acc: 0.8932 - val_loss: 0.3030 - val_acc: 0.8943\n",
            "Epoch 11/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.2972 - acc: 0.8961 - val_loss: 0.2947 - val_acc: 0.8969\n",
            "Epoch 12/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.2917 - acc: 0.8981 - val_loss: 0.2875 - val_acc: 0.8996\n",
            "Epoch 13/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.2817 - acc: 0.9018 - val_loss: 0.2773 - val_acc: 0.9033\n",
            "Epoch 14/225\n",
            "1234/1234 [==============================] - 59s 48ms/step - loss: 0.2686 - acc: 0.9068 - val_loss: 0.3007 - val_acc: 0.8974\n",
            "Epoch 15/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.2576 - acc: 0.9107 - val_loss: 0.2550 - val_acc: 0.9117\n",
            "Epoch 16/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.2478 - acc: 0.9143 - val_loss: 0.2490 - val_acc: 0.9141\n",
            "Epoch 17/225\n",
            "1234/1234 [==============================] - 59s 48ms/step - loss: 0.2395 - acc: 0.9176 - val_loss: 0.2382 - val_acc: 0.9183\n",
            "Epoch 18/225\n",
            "1234/1234 [==============================] - 59s 48ms/step - loss: 0.2317 - acc: 0.9206 - val_loss: 0.2350 - val_acc: 0.9193\n",
            "Epoch 19/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.2240 - acc: 0.9236 - val_loss: 0.2229 - val_acc: 0.9242\n",
            "Epoch 20/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.2150 - acc: 0.9268 - val_loss: 0.2124 - val_acc: 0.9279\n",
            "Epoch 21/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.2070 - acc: 0.9296 - val_loss: 0.2158 - val_acc: 0.9261\n",
            "Epoch 22/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.1994 - acc: 0.9323 - val_loss: 0.2023 - val_acc: 0.9312\n",
            "Epoch 23/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1911 - acc: 0.9351 - val_loss: 0.1935 - val_acc: 0.9344\n",
            "Epoch 24/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1846 - acc: 0.9374 - val_loss: 0.2021 - val_acc: 0.9319\n",
            "Epoch 25/225\n",
            "1234/1234 [==============================] - 59s 48ms/step - loss: 0.1784 - acc: 0.9395 - val_loss: 0.1771 - val_acc: 0.9404\n",
            "Epoch 26/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.1735 - acc: 0.9413 - val_loss: 0.1815 - val_acc: 0.9382\n",
            "Epoch 27/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1679 - acc: 0.9432 - val_loss: 0.1785 - val_acc: 0.9393\n",
            "Epoch 28/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.1607 - acc: 0.9457 - val_loss: 0.1621 - val_acc: 0.9453\n",
            "Epoch 29/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1543 - acc: 0.9479 - val_loss: 0.1556 - val_acc: 0.9476\n",
            "Epoch 30/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1527 - acc: 0.9484 - val_loss: 0.1620 - val_acc: 0.9450\n",
            "Epoch 31/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.1446 - acc: 0.9512 - val_loss: 0.1455 - val_acc: 0.9514\n",
            "Epoch 32/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1415 - acc: 0.9522 - val_loss: 0.1442 - val_acc: 0.9514\n",
            "Epoch 33/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1373 - acc: 0.9537 - val_loss: 0.1569 - val_acc: 0.9462\n",
            "Epoch 34/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1333 - acc: 0.9550 - val_loss: 0.1391 - val_acc: 0.9528\n",
            "Epoch 35/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1312 - acc: 0.9558 - val_loss: 0.1318 - val_acc: 0.9557\n",
            "Epoch 36/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1268 - acc: 0.9572 - val_loss: 0.1358 - val_acc: 0.9539\n",
            "Epoch 37/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1228 - acc: 0.9586 - val_loss: 0.1302 - val_acc: 0.9561\n",
            "Epoch 38/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1198 - acc: 0.9596 - val_loss: 0.1212 - val_acc: 0.9594\n",
            "Epoch 39/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1165 - acc: 0.9608 - val_loss: 0.1162 - val_acc: 0.9612\n",
            "Epoch 40/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1129 - acc: 0.9620 - val_loss: 0.1137 - val_acc: 0.9619\n",
            "Epoch 41/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1102 - acc: 0.9629 - val_loss: 0.1440 - val_acc: 0.9544\n",
            "Epoch 42/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1072 - acc: 0.9639 - val_loss: 0.1116 - val_acc: 0.9627\n",
            "Epoch 43/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.1047 - acc: 0.9647 - val_loss: 0.1070 - val_acc: 0.9641\n",
            "Epoch 44/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.1007 - acc: 0.9661 - val_loss: 0.1054 - val_acc: 0.9645\n",
            "Epoch 45/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0986 - acc: 0.9668 - val_loss: 0.1011 - val_acc: 0.9661\n",
            "Epoch 46/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0959 - acc: 0.9677 - val_loss: 0.0991 - val_acc: 0.9667\n",
            "Epoch 47/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0944 - acc: 0.9682 - val_loss: 0.0988 - val_acc: 0.9669\n",
            "Epoch 48/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0938 - acc: 0.9684 - val_loss: 0.0953 - val_acc: 0.9681\n",
            "Epoch 49/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0889 - acc: 0.9701 - val_loss: 0.0958 - val_acc: 0.9676\n",
            "Epoch 50/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0866 - acc: 0.9709 - val_loss: 0.0896 - val_acc: 0.9702\n",
            "Epoch 51/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0842 - acc: 0.9717 - val_loss: 0.0903 - val_acc: 0.9698\n",
            "Epoch 52/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0821 - acc: 0.9724 - val_loss: 0.0850 - val_acc: 0.9717\n",
            "Epoch 53/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0796 - acc: 0.9733 - val_loss: 0.0815 - val_acc: 0.9730\n",
            "Epoch 54/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0801 - acc: 0.9732 - val_loss: 0.0828 - val_acc: 0.9724\n",
            "Epoch 55/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0752 - acc: 0.9747 - val_loss: 0.0759 - val_acc: 0.9748\n",
            "Epoch 56/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0724 - acc: 0.9757 - val_loss: 0.0750 - val_acc: 0.9751\n",
            "Epoch 57/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0704 - acc: 0.9764 - val_loss: 0.0737 - val_acc: 0.9755\n",
            "Epoch 58/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0680 - acc: 0.9772 - val_loss: 0.0691 - val_acc: 0.9773\n",
            "Epoch 59/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0661 - acc: 0.9778 - val_loss: 0.0684 - val_acc: 0.9773\n",
            "Epoch 60/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0644 - acc: 0.9784 - val_loss: 0.0679 - val_acc: 0.9774\n",
            "Epoch 61/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0622 - acc: 0.9792 - val_loss: 0.0692 - val_acc: 0.9769\n",
            "Epoch 62/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0608 - acc: 0.9796 - val_loss: 0.0608 - val_acc: 0.9801\n",
            "Epoch 63/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0590 - acc: 0.9803 - val_loss: 0.0617 - val_acc: 0.9797\n",
            "Epoch 64/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.0579 - acc: 0.9807 - val_loss: 0.0639 - val_acc: 0.9787\n",
            "Epoch 65/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0552 - acc: 0.9816 - val_loss: 0.0598 - val_acc: 0.9801\n",
            "Epoch 66/225\n",
            "1234/1234 [==============================] - 59s 48ms/step - loss: 0.0546 - acc: 0.9817 - val_loss: 0.0620 - val_acc: 0.9794\n",
            "Epoch 67/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0530 - acc: 0.9823 - val_loss: 0.0598 - val_acc: 0.9801\n",
            "Epoch 68/225\n",
            "1234/1234 [==============================] - 61s 49ms/step - loss: 0.0517 - acc: 0.9827 - val_loss: 0.0582 - val_acc: 0.9807\n",
            "Epoch 69/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0503 - acc: 0.9832 - val_loss: 0.0612 - val_acc: 0.9796\n",
            "Epoch 70/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0489 - acc: 0.9837 - val_loss: 0.0576 - val_acc: 0.9808\n",
            "Epoch 71/225\n",
            "1234/1234 [==============================] - 59s 48ms/step - loss: 0.0482 - acc: 0.9839 - val_loss: 0.0524 - val_acc: 0.9827\n",
            "Epoch 72/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.0466 - acc: 0.9845 - val_loss: 0.0539 - val_acc: 0.9822\n",
            "Epoch 73/225\n",
            "1234/1234 [==============================] - 60s 49ms/step - loss: 0.0454 - acc: 0.9849 - val_loss: 0.0535 - val_acc: 0.9824\n",
            "Epoch 74/225\n",
            "1234/1234 [==============================] - 59s 48ms/step - loss: 0.0449 - acc: 0.9850 - val_loss: 0.0484 - val_acc: 0.9841\n",
            "Epoch 75/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.0433 - acc: 0.9856 - val_loss: 0.0470 - val_acc: 0.9847\n",
            "Epoch 76/225\n",
            "1234/1234 [==============================] - 60s 48ms/step - loss: 0.0425 - acc: 0.9859 - val_loss: 0.0464 - val_acc: 0.9849\n",
            "Epoch 77/225\n",
            "1202/1234 [============================>.] - ETA: 1s - loss: 0.0415 - acc: 0.9862"
          ]
        }
      ],
      "source": [
        "# fit the model\n",
        "nb_epochs = 225\n",
        "validation_steps = len(X_val) // batch_size\n",
        "history = model.fit(training_generator, steps_per_epoch=steps_per_epoch, epochs=nb_epochs, verbose=1, \n",
        "                              validation_data=validation_generator, validation_steps=validation_steps, \n",
        "                             use_multiprocessing=False, shuffle=True, callbacks=[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGWl_hHwDst6"
      },
      "outputs": [],
      "source": [
        "# plot the model loss and accuracy\n",
        "fig, (axis1, axis2) = plt.subplots(nrows=1, ncols=2, figsize=(16,6))\n",
        "\n",
        "# summarize history for accuracy\n",
        "axis1.plot(history.history[\"acc\"], label='Train', linewidth=3)\n",
        "axis1.plot(history.history[\"val_acc\"], label='Validation', linewidth=3)\n",
        "axis1.set_title('Model accuracy', fontsize=16, color=\"white\")\n",
        "axis1.set_ylabel('accuracy')\n",
        "axis1.set_xlabel('epoch')\n",
        "axis1.legend(loc='lower right')\n",
        "\n",
        "# summarize history for loss\n",
        "axis2.plot(history.history[\"loss\"], label='Train', linewidth=3)\n",
        "axis2.plot(history.history[\"val_loss\"], label='Validation', linewidth=3)\n",
        "axis2.set_title('Model loss', fontsize=16, color=\"white\")\n",
        "axis2.set_ylabel('loss')\n",
        "axis2.set_xlabel('epoch')\n",
        "axis2.legend(loc='upper right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}